# coding: utf-8

# ====================================================
# imports
from __future__ import annotations

import pickle

import numpy as np
from h5py import string_dtype
from numbers import Number

import numpy.typing as npt
from typing import Any
from typing import Mapping
from typing import TYPE_CHECKING

import ch5mpy
from ch5mpy import File
from ch5mpy import Group
from ch5mpy import Dataset
from ch5mpy.utils import is_sequence
from ch5mpy.h5array.array import get_size

if TYPE_CHECKING:
    from ch5mpy import H5Array


# ====================================================
# code
def write_attribute(group: Group,
                    name: str,
                    obj: Any) -> None:
    """Write a simple object as a H5 group attribute."""
    try:
        group.attrs[name] = "None" if obj is None else obj

    except TypeError:
        # since <obj> cannot be stored directly, we pickle it
        # here we use numpy's void type to allow storing bytes generated by pickle
        group.attrs[name] = np.void(pickle.dumps(obj, protocol=pickle.HIGHEST_PROTOCOL))


def write_attributes(group: Group,
                     **kwargs: Any) -> None:
    """Write multiple object as h5 group attributes."""
    for name, obj in kwargs.items():
        write_attribute(group, name, obj)


def _store_dataset(loc: Group | File,
                   name: str,
                   array: npt.NDArray[Any] | H5Array[Any] | None = None,
                   shape: tuple[int, ...] | None = None,
                   dtype: npt.DTypeLike | None = None,
                   chunks: bool | tuple[int, ...] | None = None,
                   maxshape: int | tuple[int | None, ...] | None = None,
                   fill_value: Any = None) -> Dataset[Any]:
    """Store a dataset."""
    if dtype is None:
        if array is not None:
            dtype = array.dtype

    if isinstance(dtype, type):
        str_dtype = str(dtype().dtype)
    else:
        str_dtype = str(dtype)

    if np.issubdtype(dtype, np.str_):
        array = None if array is None else array.astype(object)
        dtype = string_dtype()

    if array is not None:
        if shape is None:
            shape = array.shape

        elif shape != array.shape:
            raise ValueError("array's shape does not match the shape parameter.")

    elif shape is None:
        raise ValueError("At least one of `array` or `shape` must be provided.")

    if chunks:
        if chunks is True:      # literally `True`, not a tuple
            chunks = (get_size(ch5mpy.H5Array.MAX_MEM_USAGE),) + (1,) * (len(shape) - 1)

        if maxshape is None:
            maxshape = (None,) * len(shape)

    dset = loc.create_dataset(name, data=array, shape=shape, dtype=dtype,
                              chunks=chunks, maxshape=maxshape,
                              fillvalue=fill_value)
    dset.attrs['dtype'] = str_dtype

    return dset


def write_dataset(loc: Group | File,
                  name: str,
                  obj: Any,
                  chunks: bool | tuple[int, ...] | None = None,
                  maxshape: tuple[int, ...] | None = None) -> None:
    """Write an array-like object to a H5 dataset."""
    if isinstance(obj, Mapping):
        group = loc.create_group(name)
        write_datasets(group, **obj)
        return

    # cast to np.array if needed (to get shape and dtype)
    array = np.array(obj) if not hasattr(obj, "shape") else obj

    if name in loc.keys():
        if loc[name] is array:
            # this exact dataset is already stored > do nothing
            return

        if loc[name].shape == array.shape and loc[name].dtype == array.dtype:
            # a similar array already exists > simply copy the data
            loc[name][()] = array
            return

        # a different array was stored, delete it before storing the new array
        del loc[name]

    _store_dataset(loc, name, array, chunks=chunks, maxshape=maxshape)


def write_datasets(loc: Group | File,
                   chunks: bool | tuple[int, ...] | None = None,
                   maxshape: tuple[int, ...] | None = None,
                   **kwargs: Any) -> None:
    """Write multiple array-like objects to H5 datasets."""
    for name, obj in kwargs.items():
        write_dataset(loc, name, obj, chunks=chunks, maxshape=maxshape)


def write_object(loc: Group | File,
                 name: str,
                 obj: Any,
                 chunks: bool | tuple[int, ...] | None = None,
                 maxshape: tuple[int, ...] | None = None) -> None:
    """Write any object to a H5 file."""
    if isinstance(obj, Mapping):
        group = loc.create_group(name)
        write_objects(group, **obj, chunks=chunks, maxshape=maxshape)
        return

    if is_sequence(obj) or isinstance(obj, (Number, str)):
        write_dataset(loc, name, obj, chunks=chunks, maxshape=maxshape)
        return

    raise NotImplementedError


def write_objects(loc: Group | File,
                  chunks: bool | tuple[int, ...] | None = None,
                  maxshape: tuple[int, ...] | None = None,
                  **kwargs: Any) -> None:
    """Write multiple objects of any type to a H5 file."""
    for name, obj in kwargs.items():
        write_object(loc, name, obj, chunks=chunks, maxshape=maxshape)
